{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.templates.default = 'seaborn'\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "data.head(\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем соотношение классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898321\n",
       "1    0.101679\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеем малую долю токсичных комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальнейшие шаги:\n",
    "- Предобработка текста (удаление стоп-слов, лишних символов)\n",
    "- Токенизация \n",
    "- Лемматизация (Приведение слова к его нач.форме)\n",
    "- Векторизация корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(text):\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "    return lemmatized_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    # Удаляем все знаки и символы(кроме латинских)    \n",
    "    text = re.sub(r'[^a-zA-Z ]', ' ', text)\n",
    "    return \" \".join(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data['text'].values.astype('U')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\",\n",
       "       \"D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\",\n",
       "       \"Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\",\n",
       "       '\"\\nMore\\nI can\\'t make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It\\'s listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"',\n",
       "       \"You, sir, are my hero. Any chance you remember what page that's on?\"],\n",
       "      dtype='<U5000')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "corpus[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_corpus = [lemmatize(text_cleaner(text)) for text in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Explanation Why the edits made under my username Hardcore Metallica Fan were reverted They weren t vandalism just closure on some GAs after I voted at New York Dolls FAC And please don t remove the template from the talk page since I m retired now',\n",
       " 'D aww He match this background colour I m seemingly stuck with Thanks talk January UTC',\n",
       " 'Hey man I m really not trying to edit war It s just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page He seems to care more about the formatting than the actual info',\n",
       " 'More I can t make any real suggestion on improvement I wondered if the section statistic should be later on or a subsection of type of accident I think the reference may need tidying so that they are all in the exact same format ie date format etc I can do that later on if no one else doe first if you have any preference for formatting style on reference or want to do it yourself please let me know There appears to be a backlog on article for review so I guess there may be a delay until a reviewer turn up It s listed in the relevant form eg Wikipedia Good article nomination Transport',\n",
       " 'You sir are my hero Any chance you remember what page that s on']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_corpus[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим на train/test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(lemmatized_corpus, data['toxic'], \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: 127656\n",
      "Test shape: 31915\n"
     ]
    }
   ],
   "source": [
    "print('Train shape:', len(X_train))\n",
    "print('Test shape:', len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Векторизация корпуса и удаление стоп-слов\n",
    "\n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,1), stop_words=stopwords,\n",
    "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1 )\n",
    "\n",
    "X_train_vect = tf_idf_vect.fit_transform(X_train)\n",
    "X_test_vect = tf_idf_vect.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train vectorized shape: (127656, 41830)\n",
      "X_test vectorized shape: (31915, 41830)\n"
     ]
    }
   ],
   "source": [
    "print('X_train vectorized shape:', X_train_vect.shape)\n",
    "print('X_test vectorized shape:', X_test_vect.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Итог подготовки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе был сформирован готовый корпус текстов. Для этого мы привели слова в текстах к их начальной форме, затем убрали все лишние символы и осуществили векторизацию, т.е перевод текстов в векторное пространство"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введём константную модель, которая на любой объект будет давать ответ _toxic=0_. С ней и будет сравниваться результат остальных моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for baseline model:0.898\n"
     ]
    }
   ],
   "source": [
    "baseline_predictor = pd.Series(data=np.zeros((len(y_test))), index=y_test.index, dtype='int16')\n",
    "baseline_accuacy = accuracy_score(y_test, baseline_predictor)\n",
    "print(f'Accuracy for baseline model:{baseline_accuacy:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель лог. регрессии, а затем посмотрим на результаты кросс-валидации. В сетке переберём параметр регуляризации - C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "[CV] C=10.0, max_iter=1000 ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ C=10.0, max_iter=1000, total=  16.4s\n",
      "[CV] C=10.0, max_iter=1000 ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   16.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ C=10.0, max_iter=1000, total=  16.3s\n",
      "[CV] C=10.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=10.0, max_iter=1000, total=  16.1s\n",
      "[CV] C=10.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=10.0, max_iter=1000, total=  16.4s\n",
      "[CV] C=10.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=10.0, max_iter=1000, total=  14.2s\n",
      "[CV] C=11.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=11.0, max_iter=1000, total=  15.4s\n",
      "[CV] C=11.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=11.0, max_iter=1000, total=  15.2s\n",
      "[CV] C=11.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=11.0, max_iter=1000, total=  15.8s\n",
      "[CV] C=11.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=11.0, max_iter=1000, total=  15.7s\n",
      "[CV] C=11.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=11.0, max_iter=1000, total=  15.5s\n",
      "[CV] C=12.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=12.0, max_iter=1000, total=  14.7s\n",
      "[CV] C=12.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=12.0, max_iter=1000, total=  15.3s\n",
      "[CV] C=12.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=12.0, max_iter=1000, total=  15.1s\n",
      "[CV] C=12.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=12.0, max_iter=1000, total=  14.5s\n",
      "[CV] C=12.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=12.0, max_iter=1000, total=  15.2s\n",
      "[CV] C=13.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=13.0, max_iter=1000, total=  15.3s\n",
      "[CV] C=13.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=13.0, max_iter=1000, total=  14.7s\n",
      "[CV] C=13.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=13.0, max_iter=1000, total=  14.5s\n",
      "[CV] C=13.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=13.0, max_iter=1000, total=  14.5s\n",
      "[CV] C=13.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=13.0, max_iter=1000, total=  15.0s\n",
      "[CV] C=14.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=14.0, max_iter=1000, total=  14.8s\n",
      "[CV] C=14.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=14.0, max_iter=1000, total=  14.6s\n",
      "[CV] C=14.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=14.0, max_iter=1000, total=  18.3s\n",
      "[CV] C=14.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=14.0, max_iter=1000, total=  15.0s\n",
      "[CV] C=14.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=14.0, max_iter=1000, total=  15.4s\n",
      "[CV] C=15.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=15.0, max_iter=1000, total=  14.7s\n",
      "[CV] C=15.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=15.0, max_iter=1000, total=  14.9s\n",
      "[CV] C=15.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=15.0, max_iter=1000, total=  14.8s\n",
      "[CV] C=15.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=15.0, max_iter=1000, total=  16.7s\n",
      "[CV] C=15.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=15.0, max_iter=1000, total=  15.3s\n",
      "[CV] C=16.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=16.0, max_iter=1000, total=  17.2s\n",
      "[CV] C=16.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=16.0, max_iter=1000, total=  14.8s\n",
      "[CV] C=16.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=16.0, max_iter=1000, total=  16.8s\n",
      "[CV] C=16.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=16.0, max_iter=1000, total=  17.1s\n",
      "[CV] C=16.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=16.0, max_iter=1000, total=  17.3s\n",
      "[CV] C=17.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=17.0, max_iter=1000, total=  17.2s\n",
      "[CV] C=17.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=17.0, max_iter=1000, total=  18.9s\n",
      "[CV] C=17.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=17.0, max_iter=1000, total=  17.2s\n",
      "[CV] C=17.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=17.0, max_iter=1000, total=  16.9s\n",
      "[CV] C=17.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=17.0, max_iter=1000, total=  17.2s\n",
      "[CV] C=18.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=18.0, max_iter=1000, total=  16.8s\n",
      "[CV] C=18.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=18.0, max_iter=1000, total=  17.3s\n",
      "[CV] C=18.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=18.0, max_iter=1000, total=  17.1s\n",
      "[CV] C=18.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=18.0, max_iter=1000, total=  17.0s\n",
      "[CV] C=18.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=18.0, max_iter=1000, total=  17.1s\n",
      "[CV] C=19.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=19.0, max_iter=1000, total=  17.1s\n",
      "[CV] C=19.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=19.0, max_iter=1000, total=  17.2s\n",
      "[CV] C=19.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=19.0, max_iter=1000, total=  17.5s\n",
      "[CV] C=19.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=19.0, max_iter=1000, total=  16.9s\n",
      "[CV] C=19.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=19.0, max_iter=1000, total=  17.0s\n",
      "[CV] C=20.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=20.0, max_iter=1000, total=  19.8s\n",
      "[CV] C=20.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=20.0, max_iter=1000, total=  17.3s\n",
      "[CV] C=20.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=20.0, max_iter=1000, total=  17.4s\n",
      "[CV] C=20.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=20.0, max_iter=1000, total=  17.5s\n",
      "[CV] C=20.0, max_iter=1000 ...........................................\n",
      "[CV] ............................ C=20.0, max_iter=1000, total=  19.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed: 14.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': array([10., 11., 12., 13., 14., 15., 16., 17., 18., 19., 20.]),\n",
       "                         'max_iter': [1000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'C': np.linspace(10, 20, num = 11, endpoint = True),\n",
    "             'max_iter': [1000]}\n",
    "lr_model = LogisticRegression()\n",
    "clf = GridSearchCV(lr_model, parameters,\n",
    "                  cv=5,\n",
    "                  scoring='f1',\n",
    "                  n_jobs=-1,\n",
    "                  verbose=2)\n",
    "clf.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший F1 на CV : 0.773\n",
      "Лучший параметр C для регрессии: {'C': 13.0, 'max_iter': 1000}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Лучший F1 на CV : {clf.best_score_:.3f}\")\n",
    "print(f\"Лучший параметр C для регрессии: {clf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm = LogisticRegression(C=13, max_iter=1000)\n",
    "lrm.fit(X_train_vect, y_train)\n",
    "predict = lrm.predict(X_test_vect)\n",
    "f1_lr = f1_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на test`e 0.782\n"
     ]
    }
   ],
   "source": [
    "print(f'F1 на test`e {f1_lr:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее проверим модель лог. регресси на адекватность, т.е сравним accuracy логрега и baseline модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy на логистической регрессии 0.960\n"
     ]
    }
   ],
   "source": [
    "lrm_accuracy = accuracy_score(y_test, predict)\n",
    "print(f\"Accuracy на логистической регрессии {lrm_accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy на логреге превосходит метрику константной модели, отсюда заметно, что модель вменяема"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost_model = AdaBoostClassifier(n_estimators=100)\n",
    "ada_boost_model.fit(X_train_vect, y_train)\n",
    "pred = ada_boost_model.predict(X_test_vect)\n",
    "f1_ada = f1_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на test`e 0.711\n"
     ]
    }
   ],
   "source": [
    "print(f'F1 на test`e {f1_ada:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={'n_estimators':[500,1000,2000],'learning_rate':[.001,0.01,.1]}\n",
    "\n",
    "search=GridSearchCV(estimator=ada_boost_model,param_grid=param_grid,scoring='f1',n_jobs=-1,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-9d694f1ce97c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_vect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    685\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    664\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 666\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 random_state)\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;31m# Early termination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \"\"\"\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "search.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на test`e 0.730\n"
     ]
    }
   ],
   "source": [
    "ada_boost_model = AdaBoostClassifier(n_estimators=170)\n",
    "ada_boost_model.fit(X_train_vect, y_train)\n",
    "pred = ada_boost_model.predict(X_test_vect)\n",
    "f1_ada = f1_score(y_test, pred)\n",
    "\n",
    "print(f'F1 на test`e {f1_ada:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C': np.linspace(1, 31, num = 7, endpoint = True)}\n",
    "lsvcm = LinearSVC(max_iter = 1000)\n",
    "clf_lsvc = GridSearchCV(lsvcm, parameters,\n",
    "                  cv=5,\n",
    "                  scoring='f1',\n",
    "                  n_jobs=-1,\n",
    "                  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "[CV] C=1.0 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................................ C=1.0, total=   0.8s\n",
      "[CV] C=1.0 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................................ C=1.0, total=   0.8s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ............................................ C=1.0, total=   0.8s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ............................................ C=1.0, total=   0.9s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ............................................ C=1.0, total=   0.8s\n",
      "[CV] C=6.0 ...........................................................\n",
      "[CV] ............................................ C=6.0, total=   2.8s\n",
      "[CV] C=6.0 ...........................................................\n",
      "[CV] ............................................ C=6.0, total=   2.1s\n",
      "[CV] C=6.0 ...........................................................\n",
      "[CV] ............................................ C=6.0, total=   2.5s\n",
      "[CV] C=6.0 ...........................................................\n",
      "[CV] ............................................ C=6.0, total=   3.0s\n",
      "[CV] C=6.0 ...........................................................\n",
      "[CV] ............................................ C=6.0, total=   2.2s\n",
      "[CV] C=11.0 ..........................................................\n",
      "[CV] ........................................... C=11.0, total=   3.4s\n",
      "[CV] C=11.0 ..........................................................\n",
      "[CV] ........................................... C=11.0, total=   3.7s\n",
      "[CV] C=11.0 ..........................................................\n",
      "[CV] ........................................... C=11.0, total=   3.8s\n",
      "[CV] C=11.0 ..........................................................\n",
      "[CV] ........................................... C=11.0, total=   3.8s\n",
      "[CV] C=11.0 ..........................................................\n",
      "[CV] ........................................... C=11.0, total=   4.7s\n",
      "[CV] C=16.0 ..........................................................\n",
      "[CV] ........................................... C=16.0, total=   6.0s\n",
      "[CV] C=16.0 ..........................................................\n",
      "[CV] ........................................... C=16.0, total=   4.8s\n",
      "[CV] C=16.0 ..........................................................\n",
      "[CV] ........................................... C=16.0, total=   5.4s\n",
      "[CV] C=16.0 ..........................................................\n",
      "[CV] ........................................... C=16.0, total=   6.1s\n",
      "[CV] C=16.0 ..........................................................\n",
      "[CV] ........................................... C=16.0, total=   4.6s\n",
      "[CV] C=21.0 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................................... C=21.0, total=   6.1s\n",
      "[CV] C=21.0 ..........................................................\n",
      "[CV] ........................................... C=21.0, total=   5.4s\n",
      "[CV] C=21.0 ..........................................................\n",
      "[CV] ........................................... C=21.0, total=   6.1s\n",
      "[CV] C=21.0 ..........................................................\n",
      "[CV] ........................................... C=21.0, total=   6.1s\n",
      "[CV] C=21.0 ..........................................................\n",
      "[CV] ........................................... C=21.0, total=   6.0s\n",
      "[CV] C=26.0 ..........................................................\n",
      "[CV] ........................................... C=26.0, total=   6.5s\n",
      "[CV] C=26.0 ..........................................................\n",
      "[CV] ........................................... C=26.0, total=   6.3s\n",
      "[CV] C=26.0 ..........................................................\n",
      "[CV] ........................................... C=26.0, total=   6.4s\n",
      "[CV] C=26.0 ..........................................................\n",
      "[CV] ........................................... C=26.0, total=   6.2s\n",
      "[CV] C=26.0 ..........................................................\n",
      "[CV] ........................................... C=26.0, total=   6.2s\n",
      "[CV] C=31.0 ..........................................................\n",
      "[CV] ........................................... C=31.0, total=   6.6s\n",
      "[CV] C=31.0 ..........................................................\n",
      "[CV] ........................................... C=31.0, total=   6.0s\n",
      "[CV] C=31.0 ..........................................................\n",
      "[CV] ........................................... C=31.0, total=   6.7s\n",
      "[CV] C=31.0 ..........................................................\n",
      "[CV] ........................................... C=31.0, total=   6.3s\n",
      "[CV] C=31.0 ..........................................................\n",
      "[CV] ........................................... C=31.0, total=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                 fit_intercept=True, intercept_scaling=1,\n",
       "                                 loss='squared_hinge', max_iter=1000,\n",
       "                                 multi_class='ovr', penalty='l2',\n",
       "                                 random_state=None, tol=0.0001, verbose=0),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': array([ 1.,  6., 11., 16., 21., 26., 31.])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lsvc.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучший показатель f1 на кросс-валидации : 0.777\n",
      "Параметр регуляризации для лучшей модели: {'C': 1.0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"f1 на кросс-валидации : {clf_lsvc.best_score_:.3f}\")\n",
    "print(f\"Параметр регуляризации для лучшей модели: {clf_lsvc.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvcm = LinearSVC(C=1, max_iter=1000)\n",
    "lsvcm.fit(X_train_vect, y_train)\n",
    "predict = lsvcm.predict(X_test_vect)\n",
    "f1_lsvc = f1_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 на тестовой выборке: 0.787\n"
     ]
    }
   ],
   "source": [
    "print(f\"f1 на тестовой выборке: {f1_lsvc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Был проведён анализ тональности текстов. В исследовании были задействованы 3 модели **Logistic Regression, LinearSVC, AdaBoostClassifier**.\n",
    "\n",
    " - Модель LinearSVC показала высший F1-score (0,787). \n",
    " - Logistic Regression(0.782)  и она также прошла проверку на вменяемость по метрике accuracy (> 0.9)\n",
    " - AdaBoost (0.73)\n",
    "\n",
    "Возможно, что мы могли получить лучшие результаты для AdaBoost, если его потюнить. Но лог.регрессия и svm с задачей справились порог для f1 (0.75) пройден."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 6973,
    "start_time": "2021-08-07T08:50:32.282Z"
   },
   {
    "duration": 747,
    "start_time": "2021-08-07T08:51:04.493Z"
   },
   {
    "duration": 870,
    "start_time": "2021-08-07T08:51:13.591Z"
   },
   {
    "duration": 7,
    "start_time": "2021-08-07T11:56:07.464Z"
   },
   {
    "duration": 263,
    "start_time": "2021-08-07T11:56:29.818Z"
   },
   {
    "duration": 873,
    "start_time": "2021-08-07T11:57:37.772Z"
   },
   {
    "duration": 18,
    "start_time": "2021-08-07T11:57:50.020Z"
   },
   {
    "duration": 1591,
    "start_time": "2021-08-07T12:00:40.151Z"
   },
   {
    "duration": 29,
    "start_time": "2021-08-07T12:03:29.413Z"
   },
   {
    "duration": 466,
    "start_time": "2021-08-07T12:03:29.444Z"
   },
   {
    "duration": 239,
    "start_time": "2021-08-07T12:03:33.468Z"
   },
   {
    "duration": 248,
    "start_time": "2021-08-07T12:04:56.104Z"
   },
   {
    "duration": 4,
    "start_time": "2021-08-07T12:08:56.128Z"
   },
   {
    "duration": 4,
    "start_time": "2021-08-07T12:10:38.990Z"
   },
   {
    "duration": 2718,
    "start_time": "2021-08-07T12:11:20.610Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-07T12:11:32.007Z"
   },
   {
    "duration": 483,
    "start_time": "2021-08-07T12:11:52.225Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-07T12:12:01.132Z"
   },
   {
    "duration": 131931,
    "start_time": "2021-08-07T12:14:09.269Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-07T12:24:48.132Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-07T12:27:35.582Z"
   },
   {
    "duration": 377,
    "start_time": "2021-08-07T12:28:13.025Z"
   },
   {
    "duration": 415,
    "start_time": "2021-08-07T12:28:26.081Z"
   },
   {
    "duration": 78,
    "start_time": "2021-08-07T12:28:31.884Z"
   },
   {
    "duration": 402,
    "start_time": "2021-08-07T12:29:30.357Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-07T12:30:08.078Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-07T12:35:03.816Z"
   },
   {
    "duration": 12183,
    "start_time": "2021-08-07T12:37:31.188Z"
   },
   {
    "duration": 64,
    "start_time": "2021-08-07T12:38:27.271Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-07T12:38:56.381Z"
   },
   {
    "duration": 10922,
    "start_time": "2021-08-07T12:39:33.197Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-07T12:39:45.765Z"
   },
   {
    "duration": 113,
    "start_time": "2021-08-07T12:43:59.591Z"
   },
   {
    "duration": 386,
    "start_time": "2021-08-07T12:44:26.274Z"
   },
   {
    "duration": 12,
    "start_time": "2021-08-07T12:44:42.787Z"
   },
   {
    "duration": 927420,
    "start_time": "2021-08-07T12:54:27.745Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-07T13:09:55.167Z"
   },
   {
    "duration": 567,
    "start_time": "2021-08-07T14:27:22.590Z"
   },
   {
    "duration": -127,
    "start_time": "2021-08-07T14:27:47.979Z"
   },
   {
    "duration": 17611,
    "start_time": "2021-08-07T14:27:59.363Z"
   },
   {
    "duration": 382,
    "start_time": "2021-08-07T14:29:01.780Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-07T14:29:32.461Z"
   },
   {
    "duration": 384,
    "start_time": "2021-08-07T14:34:38.491Z"
   },
   {
    "duration": 8,
    "start_time": "2021-08-07T14:34:47.881Z"
   },
   {
    "duration": 424,
    "start_time": "2021-08-07T14:50:49.102Z"
   },
   {
    "duration": 714,
    "start_time": "2021-08-07T14:55:43.280Z"
   },
   {
    "duration": -134,
    "start_time": "2021-08-07T14:55:44.132Z"
   },
   {
    "duration": 7323,
    "start_time": "2021-08-07T14:55:53.922Z"
   },
   {
    "duration": 824,
    "start_time": "2021-08-07T14:56:01.249Z"
   },
   {
    "duration": 35,
    "start_time": "2021-08-07T14:56:02.077Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-07T14:56:02.116Z"
   },
   {
    "duration": 45,
    "start_time": "2021-08-07T14:56:02.125Z"
   },
   {
    "duration": 2779,
    "start_time": "2021-08-07T14:56:02.172Z"
   },
   {
    "duration": 9,
    "start_time": "2021-08-07T14:56:04.953Z"
   },
   {
    "duration": 132180,
    "start_time": "2021-08-07T14:56:04.965Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-07T14:58:17.149Z"
   },
   {
    "duration": 130,
    "start_time": "2021-08-07T14:58:17.157Z"
   },
   {
    "duration": -107,
    "start_time": "2021-08-07T14:58:17.396Z"
   },
   {
    "duration": -111,
    "start_time": "2021-08-07T14:58:17.402Z"
   },
   {
    "duration": -119,
    "start_time": "2021-08-07T14:58:17.411Z"
   },
   {
    "duration": -121,
    "start_time": "2021-08-07T14:58:17.415Z"
   },
   {
    "duration": -249,
    "start_time": "2021-08-07T14:58:17.544Z"
   },
   {
    "duration": -253,
    "start_time": "2021-08-07T14:58:17.550Z"
   },
   {
    "duration": -258,
    "start_time": "2021-08-07T14:58:17.556Z"
   },
   {
    "duration": -263,
    "start_time": "2021-08-07T14:58:17.563Z"
   },
   {
    "duration": -271,
    "start_time": "2021-08-07T14:58:17.572Z"
   },
   {
    "duration": -277,
    "start_time": "2021-08-07T14:58:17.580Z"
   },
   {
    "duration": -283,
    "start_time": "2021-08-07T14:58:17.587Z"
   },
   {
    "duration": -293,
    "start_time": "2021-08-07T14:58:17.599Z"
   },
   {
    "duration": 4,
    "start_time": "2021-08-07T14:59:35.791Z"
   },
   {
    "duration": 82,
    "start_time": "2021-08-07T14:59:35.801Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-07T14:59:35.900Z"
   },
   {
    "duration": 10587,
    "start_time": "2021-08-07T14:59:35.908Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-07T14:59:46.500Z"
   },
   {
    "duration": 12,
    "start_time": "2021-08-07T14:59:46.508Z"
   },
   {
    "duration": 911934,
    "start_time": "2021-08-07T14:59:46.523Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-07T15:14:58.461Z"
   },
   {
    "duration": 167,
    "start_time": "2021-08-07T15:14:58.470Z"
   },
   {
    "duration": -140,
    "start_time": "2021-08-07T15:14:58.781Z"
   },
   {
    "duration": -144,
    "start_time": "2021-08-07T15:14:58.787Z"
   },
   {
    "duration": -171,
    "start_time": "2021-08-07T15:14:58.816Z"
   },
   {
    "duration": -183,
    "start_time": "2021-08-07T15:14:58.830Z"
   },
   {
    "duration": 17858,
    "start_time": "2021-08-07T15:16:26.105Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-07T15:16:43.966Z"
   },
   {
    "duration": 8,
    "start_time": "2021-08-07T15:16:47.486Z"
   },
   {
    "duration": 103558,
    "start_time": "2021-08-07T15:16:55.479Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-07T15:18:39.040Z"
   },
   {
    "duration": 9,
    "start_time": "2021-08-07T15:20:47.061Z"
   },
   {
    "duration": 1072747,
    "start_time": "2021-08-07T15:21:13.338Z"
   },
   {
    "duration": -376,
    "start_time": "2021-08-07T15:39:06.464Z"
   },
   {
    "duration": 291323,
    "start_time": "2021-08-07T15:40:03.170Z"
   },
   {
    "duration": 73146,
    "start_time": "2021-08-07T15:45:13.833Z"
   },
   {
    "duration": 124447,
    "start_time": "2021-08-07T15:48:17.594Z"
   },
   {
    "duration": 167886,
    "start_time": "2021-08-07T15:50:26.631Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-07T15:54:05.419Z"
   },
   {
    "duration": 431,
    "start_time": "2021-08-07T15:54:09.553Z"
   },
   {
    "duration": 156943,
    "start_time": "2021-08-07T15:54:16.854Z"
   },
   {
    "duration": 7,
    "start_time": "2021-08-07T15:56:53.801Z"
   },
   {
    "duration": 9784,
    "start_time": "2021-08-07T15:58:24.477Z"
   },
   {
    "duration": 4,
    "start_time": "2021-08-07T15:58:38.399Z"
   },
   {
    "duration": 15315,
    "start_time": "2021-08-07T15:58:50.046Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-07T15:59:05.364Z"
   },
   {
    "duration": 9799,
    "start_time": "2021-08-07T15:59:18.970Z"
   },
   {
    "duration": 4,
    "start_time": "2021-08-07T15:59:28.773Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-07T16:02:38.952Z"
   },
   {
    "duration": 490,
    "start_time": "2021-08-07T16:02:38.960Z"
   },
   {
    "duration": -74,
    "start_time": "2021-08-07T16:02:39.526Z"
   },
   {
    "duration": -77,
    "start_time": "2021-08-07T16:02:39.531Z"
   },
   {
    "duration": 392,
    "start_time": "2021-08-07T16:03:02.290Z"
   },
   {
    "duration": -64,
    "start_time": "2021-08-07T16:03:02.749Z"
   },
   {
    "duration": -68,
    "start_time": "2021-08-07T16:03:02.755Z"
   },
   {
    "duration": 8440,
    "start_time": "2021-08-07T16:03:53.171Z"
   },
   {
    "duration": 860,
    "start_time": "2021-08-07T16:04:01.614Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-07T16:04:22.089Z"
   },
   {
    "duration": 8,
    "start_time": "2021-08-07T16:04:22.113Z"
   },
   {
    "duration": 2937,
    "start_time": "2021-08-07T16:04:22.124Z"
   },
   {
    "duration": 7,
    "start_time": "2021-08-07T16:04:25.065Z"
   },
   {
    "duration": 150773,
    "start_time": "2021-08-07T16:04:25.075Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-07T16:06:55.850Z"
   },
   {
    "duration": 7,
    "start_time": "2021-08-07T16:06:55.858Z"
   },
   {
    "duration": 117,
    "start_time": "2021-08-07T16:06:55.868Z"
   },
   {
    "duration": 13,
    "start_time": "2021-08-07T16:06:55.988Z"
   },
   {
    "duration": 12168,
    "start_time": "2021-08-07T16:06:56.006Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-07T16:07:08.176Z"
   },
   {
    "duration": 4,
    "start_time": "2021-08-07T16:08:28.466Z"
   },
   {
    "duration": 141,
    "start_time": "2021-08-07T16:08:28.479Z"
   },
   {
    "duration": 7,
    "start_time": "2021-08-07T16:08:28.623Z"
   },
   {
    "duration": 601,
    "start_time": "2021-08-07T16:22:48.476Z"
   },
   {
    "duration": 8067,
    "start_time": "2021-08-07T16:23:37.647Z"
   },
   {
    "duration": 825,
    "start_time": "2021-08-07T16:23:45.716Z"
   },
   {
    "duration": 17,
    "start_time": "2021-08-07T16:23:46.544Z"
   },
   {
    "duration": 4,
    "start_time": "2021-08-07T16:23:46.563Z"
   },
   {
    "duration": 34,
    "start_time": "2021-08-07T16:23:46.570Z"
   },
   {
    "duration": 2789,
    "start_time": "2021-08-07T16:23:46.607Z"
   },
   {
    "duration": 15,
    "start_time": "2021-08-07T16:23:49.402Z"
   },
   {
    "duration": 145765,
    "start_time": "2021-08-07T16:23:49.422Z"
   },
   {
    "duration": 16,
    "start_time": "2021-08-07T16:26:15.190Z"
   },
   {
    "duration": 7,
    "start_time": "2021-08-07T16:26:15.209Z"
   },
   {
    "duration": 127,
    "start_time": "2021-08-07T16:26:15.219Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-07T16:26:15.350Z"
   },
   {
    "duration": 11913,
    "start_time": "2021-08-07T16:26:15.359Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-07T16:26:27.274Z"
   },
   {
    "duration": 1157,
    "start_time": "2021-08-07T16:26:27.283Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-07T16:26:28.444Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
